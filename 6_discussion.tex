\section{Discussion} % (fold)
\label{sec:discussion}

In this chapter we will pull together our findings from Chapter~\ref{sec:technology_assessment} and~\ref{sec:clinical_context} and discuss alternative approaches, strengths and weaknesses with this research project. 

We believe the usage of smart devices in health care will increase in the coming years, and that the amount of cables will decrease. A ubiquitous future where both medical staff and patients use their private or hospital provided smart/touch devices as a tools in treatment and everyday medical related tasks, seems probable in a not too distant future. Some forms of this have already been deployed, like AFGA Healthcare's ORBISme! tablet sized EMR-device, being used in Germany today \cite{newRef:271}. 

There is however an important difference between consumer technology and medical devices. But with the growing interest for personal health monitoring within the consumer market, this distinction easily becomes blurry. Although not having any diagnostic value, it is not improbable that consumer devices soon will see it's way into a medical setting one way or the other.\footnote{ Just recently was the first reported case of medical professionals using historic data form a personal fitness tracker to make an informed, life saving medical decision \cite{newRef:29}.}

In the Section~\ref{sec:technology_assessment} we presented a solution where patient's touch devices was used as a WBAN hub, a mobile gateway connecting WBAN sensors to local area network and external services. On the same side, the consumer market has recently showed an increased interest in ``smart access points'' or ``IoT hubs''. These are WiFi access points with built in support for Bluetooth Smart and 802.15.4 in addition to the standard 802.11.X interface.\footnote{ For more information, see OnHub WiFi router from Google \cite{newRef:60} and Cassia Hub Bluetooth Router \cite{newRef:61}.} Deciding on whether the sensor devices should communicate directly with a smart access point, or through a personal gateway, is an important discussion as pointed out in the paper ``The Internet of Things Has a Gateway Problem'' by Zachariah et. al.~\cite{Zachariah:2015cm}. in the following section we will discuss the possibilities and restrictions with our chosen architecture.

\subsection{Toward a multi-vendor situation} % (fold)
\label{sub:toward_a_multi_vendor_situation}

% subsection toward_a_multi_vendor_situation (end)
In Section~\ref{sec:clinical_context} we saw how single-manufacturer, specialized monitoring solutions are deployed at two Norwegian hospitals today. We recognize that this solution does not afford clinical WBAN support, and propose that tomorrow's clinical environment will be characterized by widespread use of sensory technology delivered by different providers and manufacturers.

For our proposed design we chose a two-tier architecture based on a personal\footnote{ Personal in the sense that each patient has it's own gateway. Whether or not these are private devices or hostpial provided raises several security and privacy questions which is the topic for another discussion entirely.}, mobile gateway. To enable a multi-manufacturer sensor environment and ensure interoperability in a scalable manner, we proposed using a repository pattern where a mobile gateway could install the ``profiles'' required for mapping sensor data to the correct formats based on the \emph{context}, i.e. what sensors was connected, what is the patient's condition, and at what unit in what hostpial is the patient located in. 

However there are tradeoffs with this solution. Making a single gateway the sink of several sensors organized in a WBAN creates a single point of failure, as well as a bottleneck. As mentioned in Section~\ref{sub:wireless_body_area_networks}, previous research have proposed categorizing WBAN data in different tiers, based on clinical priority. A real-time ECG stream may be of higher clinical value and have higher QoS requirements than the occasional temperature measurement.\footnote{ Note that deep Vein Thrombosis, or blood clots, can be detected by sudden temperature changes in extremities.} With a single point of failure, ensuring the personal gateway is working properly will become of outmost importance, as a faulty gateway will not only take down the low priority sensor measurements, but also the critical ones. It is worth noting that today's telemetry solutions operate with zero downtime according to one of the clinical engineers we talked to.

As suggested by Shahamabadi et. al.~\cite{Shahamabadi:2013df}, this architecture is also susceptible to creating a bottleneck. With a growing number of sensor nodes participating in the WBAN, the amount of data being routed through the gateway increases, and the available capacity for intermediate analysis or other processing such as data transformation (as suggested in Section~\ref{sub:system_architecture}) decreases. 

An alternate approach involve using mobile gateway just as a facilitator for ``administrative'' tasks like coordinating access point handoff and roaming on behalf of the WBAN. This solution require that the WBAN sensors send physiological data directly to a smart access point. This proposition solves the problem of the mobile gateway becoming a bottleneck because data does not have to be routed through the gateway. A smart access point would also have more resources for doing intermediate data-processing~\cite{DrAmirMohammadRahmani:2014vx}. However, there is no silver bullet, as this has approach involve a higher energy consumption: With this organization the node antennas would have to consume more energy in order to send data directly to an access point/boarder router which would typically be located further away than the mobile gateway. 

We would also suggest this reduces the flexibility and interoperability of he monitoring solution. Should the backend monitoring system not be developed by the same manufacturer as the WBAN nodes, data need to be transformed into compliant application layer data formats for the information exchange.\footnote{ This should indeed be standardized between manufacturers and wireless protocols, but from the experience of HL7 and OpenEHR we know this to be a hard problem.} From a practical standpoint, we believe this transformation and similar pre-processing of data scales better at a personal gateway tier. Based on the assumption that the environment will be crowded by similar sensors from different manufacturers, we believe it is easier for personal gateways to maintain this responsibility independently, rather than all access points supporting all sensors present in the clinical setting.

% subsection monitoring_architecture (end)

\subsection{Research methods} % (fold)
\label{ssub:research_methods}

Working with this many different components and across several domains have also proven to be a challenge. As mentioned in the introduction, scoping this project had to be done along the way. Because the goals and intentions also shifted, we ended up making decisions that had to be revisited and in some cases undone at a later point.

Initially we were interested in the practical organization of a future, ubiquitous and distributed monitoring solution based on personal touch devices. We asked questions like ``How could alarm triggering events be distributed to different clinicians not located at a central monitoring station?'', ``How can clinicians be assured that patient sensors have enough battery for registering an important event? How does this scale?''. However, these questions was in them self based on assumptions about systems that did not yet exist. Therefore we saw the need for taking a step back and investigate todays existing practices, and the more fundamental aspects of ECG and wireless technologies. We recognize that the practical organization and structure of a wireless and ubiquitous monitoring solution might be a relevant problem statement in the future.

After taking a step back, we realized two things: A multi-manufacturer environment is not well supported by todays hostpial infrastructure. This is a fundamental requirement in a future where patients in a larger degree capture sensing information about their bodies outside the hospital. 

And from previous literature very few define a clear link between the research and the indented use. As we learned, establishing this intended use is necessary in order to say anything about minimum requirements like throughput, and end-to-end latency. And as we discovered, even when having established a intended use, deciding on these metrics are still no easy task.

After having set the path we did, we are satisfied with the decision of comparing two different hospitals. As we visited the second hospital, several misconceptions were cleared and we got a broadened view, especially on the organization of patients and how the the practice of on-demand monitoring were conducted in relation to the telemetry monitoring. The challenge with qualitative research methods however, is to convert increased personal insight and experience, into knowledge for everyone else. We took an explanatory approach to this in Chapter~\ref{sec:clinical_context}, where we focused on explaining the systems and practices in a logical manner. We did not structure the chapter according to the source of the information, and rather focused on mixing sources. Hopefully this created a more compound impression of today's systems and practices.

We spent a lot of time finding the minimum requirements for ECG, without ever finding any gold standards. This is why we present our own guidelines to this in Chapter~\ref{sec:technology_assessment}. Although we searched literature, the reason we didn't find this might be related to our approach and research strategy. For the technical aspects of our prototype, the heavy focus on practice and use cases did not play as big of a role as we first imagined it to do. An alternative approach could have been to target departments and instances at a higher organizational level for our interviews. Here access to standardization documents and practices might be more accessible, as compliance is usually the concern of middle, and higher level management. However, this approach however could easily suffered from a mismatch between the general guidelines and the technology deployed in practice. This would also increase turnover times, meaning a lot of time would have gone by waiting for answers from the respective higher level organizational departments.

In terms of our data collection, one thing is clear: Getting information from the manufacturers and solution providers is not worth pursuing unless a collaboration or sponsorship is established before the research begins. The time spent running down dead ends in order to find ECG related technical specifications on commercial solutions, was in the end deemed unproductive.

In retrospect we acknowledge that ISO Standards probably would have given us a good insight on the matter, especially ISO 11073-91064:2009 and ISO/IEEE 11073-10406:2012.


% subsubsection research_methods (end)

\subsection{Implementation} % (fold)
\label{sub:implementation}

% TODO Why did we not implement the proposed repository pattern?

Gateway: In retrospect, we see that aiming for making a flexible solution took much more time to develop, and proved to be generate more edge cases, making the experimentation more prone to errors. Because of the complex setup of our end-to-end latency experiment, more time could have gone into planning this making it more robust. In terms of the gateway, we could have focused less on the user interface. One alternative approach could have been to hard-code the devices, characteristics and endpoints into the gateway, which could have eased the implementation, debugging and testing. 

By the time were conducting the first trails of the experiment, we saw that the code (especially on the gateway) did not perform well over time, which was critical for our experiment. We had to do modifications on the fly during the experimentation phase in order to make everything work. We unit tested the individual components manually as we developed, but we left little time for integration tests before conducting the experiment. Had this been planned better we would have reserved time for integration tests. All in all, we see that testing and debugging the time synchronizing on both clients, as well as working with the control flow and user interface of the gateway proved to be most time consuming. It should be mentioned that we intentionally spent as little time as possible on writing custom code for the sensor board. This was because we had little experience with hardware and software development for low energy development kits. 

Implementation wise we admit more time should have been put into prioritizing reliability over functionality.

% subsection implementation (end)

\subsection{Results} % (fold)
\label{sub:results}

% subsection results (end)

We originally ran the end-to-end experiment for 16 hours during both during the night and throughout the day. This was done to see if there was any noticeable effect on other network traffic which would increase during the day. However, due to the lack of integration tests, we discovered an error with some of the timestamps that invalidated the whole experiment.

\begin{itemize}

  \item Results. Discuss them.
  \item TODO We have not looked into signal nor data compression.
  \item TODO Network disadvantage - we had no control over the network traffic. To account for this we could have conducted the experiment from different locations, and over longer periods of time. Important to note that this is conducted only at application layer.
  \item TODO battery of gateway does also play an important role

\end{itemize}


% subsubsection results (end)


\subsection{Future work} % (fold)
\label{sub:future_work}

% subsection future_work (end)

From a priori knowledge and studying Bluetooth Smart we know that the biggest energy consumer is the radio during the actual wireless transmission. In essence, version 4.0 of Bluetooth were able to reduce the energy consumption drastically compared to previous versions by powering off the radio in between events, instead of keeping a persistent connection. Based on this and our insight in today's practices we realize that there might be worth investigating radically different monitoring practices - like self-monitoring sensors. There is a trade off between doing onboard analysis on the sensor chip versus streaming the data continuously to a WBAN gateway which have to be investigated further. It might be more energy efficient to implement algorithms for analyzing sampled data on the sensors themselves and only transmit data on demand from clinicians or when deviations from given thresholds occur.

Exploring the boundaries of classical monitoring is exiting, and might be proven to yield results: During one interview with one of the medical professionals it was mentioned that in his experience, the prevalence of cardiac abnormalities of medical interest might happen during physically straining activities like walking stairs etc. However, today they had no practical way of seeing this correlation. The only place where you can monitor the real-time ECG stream is at the central monitoring station. A great deal of planning and synchronization would have to happen in order to conduct a simple ECG-test on a patient under physically strain: One would have to record the time and place while watching the patient doing the activity, then return to the monitoring central and look at the history in order to get a clear view of how the patient's heart reacted to the activity. A better solution would be ability to watch the ECG on a tablet device while observing the patient doing the activity. An improved version of this could record indoor location, number of steps and altitude together with the ECG. This way, the medical professional wouldn't have to consult with neither the patient nor the monitoring central. They could just look at the historic ECG data with activity data overlaid.

Should small, inexpensive and available patient monitoring solutions enable monitoring of every patient, regardless of medical condition, problems regarding data storage and compression will have to be addressed. Our calculations from Section~\ref{ssub:throughput} show that collecting raw ECG data from a single patient amount to between 388,8 megabyte\footnote{3 leads, 24 bit sample size and 500 Hz sampling rate} and 3110,4 megabyte\footnote{3 leads, 64 bit sample size and 1500 Hz sampling rate} on a daily basis. This is only raw data, and packaged in a standard compliant data format, this data would occupy a lot of storage. Yearly, only the raw data amounts to a Terabyte of data per patient on a single physiological metric.

% subsubsection future_work (end)

% section discussion (end)